# MLFromScratch

## 9 Best Machine Learning Models

1. Linear Regression: Linear regression is one of the first machine learning models that you should learn about. It’s a simple way to measure how variables are related, which makes it pretty easy to understand. If you want to predict house prices based on square footage or number of bedrooms — this would be one way to do so! After training, linear regression produces an equation for the line that best fits the data.
2. Logistic Regression: Logistic regression is another model that you should learn early on. Logistic regression is used when the dependent variable is categorical (i.e., has only a limited number of possible values). It can be used to predict whether something will happen (e.g., whether or not someone will buy a product) or to identify which factors are most important in determining the outcome of interest.
3. Naive Bayes: The Naive Bayes algorithm is a simple classification algorithm that is often used for text categorization. It is based on the Bayes theorem and can be used for both classification and regression tasks. The way they work is by using statistical methods to predict whether a new example belongs to one category or another, based on the features it has been assigned.
4. Principal Component Analysis: Principal Component Analysis (PCA) is a technique used to reduce the number of dimensions in a dataset. It does this by identifying the principal components, which are the directions that account for the most variance in the data. PCA can be used to simplify data visualization and improve performance of machine learning models.
5. K Nearest Neighbor: The k nearest neighbor algorithm (knn) is a simple machine learning model that stores all available cases and classifies new cases by similarity to these known cases. The way they work is by looking at the properties of a set of training examples, then using this information to predict whether new examples have similar or different properties from these known cases. This allows them to make good predictions even if you only have a small amount of data.
6. K Means Clustering: K-Means clustering is a technique used for cluster analysis, which is the process of grouping data points into clusters. It can be used to identify patterns in data and improve performance of machine learning models.
7. Decison Tree: Decision trees are another type of machine learning model that is commonly used for classification tasks. They work by splitting the set of data into smaller and smaller subsets until each subset contains only instances with similar properties, which means you can easily classify new examples by looking at their features relative to where they fall in this tree structure.
8. Random Forest: Random forest is a type of ensemble machine learning model, which means it is created by combining multiple models to make one. Ensemble methods are known for being particularly good at reducing overfitting. In the case of random forests, this involves creating many decision trees and then using them to vote on what the best prediction would be in each instance.
9. Support Vector Machine: A Support Vector Machine (SVM) is a supervised learning algorithm that can be used for both classification and regression tasks. It creates a hyperplane to separate different classes of data in your dataset, maximizing the distance between them while trying to minimize errors from incorrectly classifying examples. Support vector machines have been shown to perform well with high-dimensional data, and are often used for text classification or image recognition tasks.
